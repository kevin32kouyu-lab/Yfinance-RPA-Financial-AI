import yfinance as yf
import pandas as pd
import os
import time
import random
import requests
import io
from tqdm import tqdm

# ==================== 1. é…ç½®åŒºåŸŸ ====================
PROXY_URL = 'http://127.0.0.1:10808'

# è·¯å¾„é…ç½®
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
US_DATA_ROOT = os.path.join(PROJECT_ROOT, "us_stocks_data") 

# ä¿å­˜ä½ç½®
DIRS = {
    "ETF": os.path.join(US_DATA_ROOT, "us_etf_1h"),
    "FUTURE": os.path.join(US_DATA_ROOT, "us_future_1h")
}

for d in DIRS.values():
    os.makedirs(d, exist_ok=True)

# [æ–°å¢] å¤±è´¥æ—¥å¿—æ–‡ä»¶
FAILED_LOG_FILE = os.path.join(CURRENT_DIR, "us_mining_failed.csv")

# è¿›åº¦æ–‡ä»¶ (ç”¨äºå»é‡)
PROGRESS_FILE = os.path.join(CURRENT_DIR, "progress.txt")

# ==================== 2. ç¯å¢ƒåˆå§‹åŒ– ====================
os.environ['HTTP_PROXY'] = PROXY_URL
os.environ['HTTPS_PROXY'] = PROXY_URL

# ==================== 3. è·å–ç›®æ ‡æ¸…å• ====================

def get_existing_tickers():
    if not os.path.exists(PROGRESS_FILE):
        return set()
    with open(PROGRESS_FILE, 'r') as f:
        existing = {line.strip() for line in f if line.strip()}
    print(f"ğŸ“‹ ç°æœ‰åº“å­˜(Progress): {len(existing)} åª")
    return existing

def get_us_etf_list():
    print("\nğŸ“¡ æ­£åœ¨è·å–ç¾è‚¡ ETF åå•...")
    url = "https://raw.githubusercontent.com/rreichel3/US-Stock-Symbols/main/etf/etf_symbols_list.csv"
    try:
        resp = requests.get(url, timeout=30)
        if resp.status_code == 200:
            df = pd.read_csv(io.StringIO(resp.text))
            tickers = df['symbol'].dropna().unique().tolist()
            print(f"âœ… è·å–æˆåŠŸ: {len(tickers)} åª")
            return tickers
    except Exception as e:
        print(f"âŒ è·å–å¤±è´¥: {e}")
    
    print("âš ï¸ ä½¿ç”¨å†…ç½®æ ¸å¿ƒ ETF åˆ—è¡¨ä½œä¸ºå¤‡ç”¨")
    return ["SPY", "QQQ", "IWM", "GLD", "SLV", "TQQQ", "SQQQ", "ARKK", "XLK", "XLF", "XLE", "VXX"]

def get_futures_list():
    # æ ¸å¿ƒæœŸè´§ç™½åå•
    return [
        "ES=F", "NQ=F", "YM=F", "RTY=F", "VIX=F", # æŒ‡æ•°
        "CL=F", "NG=F", "BZ=F",                   # èƒ½æº
        "GC=F", "SI=F", "HG=F",                   # é‡‘å±
        "ZN=F", "ZB=F",                           # åˆ©ç‡
        "DX=F", "6E=F", "6J=F",                   # å¤–æ±‡
        "BTC=F", "ETH=F"                          # åŠ å¯†
    ]

# ==================== 4. ä¸‹è½½æ ¸å¿ƒé€»è¾‘ (å¸¦æ—¥å¿—) ====================

def download_batch(category_name, tickers, save_dir, existing_set):
    # è¿‡æ»¤é€»è¾‘
    targets = []
    for t in tickers:
        if t in existing_set: continue
        # æœŸè´§æ–‡ä»¶åç‰¹æ®Šå¤„ç† (= -> _)
        fname = t.replace('=', '_') + "_1h.csv"
        if os.path.exists(os.path.join(save_dir, fname)): continue
        targets.append(t)
        
    print(f"\nğŸš€ [{category_name}] ä»»åŠ¡: {len(targets)} / {len(tickers)}")
    
    if not targets:
        return []

    success_count = 0
    failed_list = [] # [æ–°å¢] æ”¶é›†å¤±è´¥è®°å½•
    
    pbar = tqdm(targets, unit="code")
    
    for ticker in pbar:
        try:
            pbar.set_description(f"â¬‡ï¸ {category_name}: {ticker}")
            
            # ä¸‹è½½
            df = yf.download(ticker, period="2y", interval="1h", progress=False)
            
            if df.empty:
                # [è®°å½•] ç©ºæ•°æ®
                failed_list.append({"Category": category_name, "Ticker": ticker, "Reason": "Empty Data"})
                continue

            # å¤„ç†
            if df.index.tz is None:
                df.index = df.index.tz_localize('UTC')
            df.index = df.index.tz_convert('America/New_York')

            df.reset_index(inplace=True)
            df['Ticker'] = ticker
            
            # ä¿å­˜æ–‡ä»¶åå¤„ç†
            safe_filename = ticker.replace('=', '_') + "_1h.csv"
            file_path = os.path.join(save_dir, safe_filename)
            
            # åˆ—å¤„ç†
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.get_level_values(0)
            
            cols = ['Datetime', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume']
            save_df = df[[c for c in cols if c in df.columns]]
            
            if not save_df.empty:
                save_df.to_csv(file_path, index=False)
                success_count += 1
            else:
                failed_list.append({"Category": category_name, "Ticker": ticker, "Reason": "No Columns"})

            time.sleep(random.uniform(0.5, 1.5))

        except Exception as e:
            # [è®°å½•] æŠ¥é”™
            err_msg = str(e)[:100]
            failed_list.append({"Category": category_name, "Ticker": ticker, "Reason": err_msg})
            time.sleep(1)

    print(f"ğŸ [{category_name}] å®Œæˆ: âœ…æˆåŠŸ {success_count} | âŒå¤±è´¥ {len(failed_list)}")
    return failed_list

# ==================== 5. ä¸»ç¨‹åº ====================

def main():
    print("="*50)
    print("ğŸ‡ºğŸ‡¸ ç¾è‚¡å…¨å¸‚åœºæŒ–æ˜ (V2 - With Log)")
    print("="*50)
    
    existing = get_existing_tickers()
    etf_list = get_us_etf_list()
    future_list = get_futures_list()
    
    all_failures = []
    
    # æ‰§è¡Œå¹¶æ”¶é›†å¤±è´¥è®°å½•
    fails_fut = download_batch("Futures", future_list, DIRS["FUTURE"], existing)
    all_failures.extend(fails_fut)
    
    fails_etf = download_batch("ETFs", etf_list, DIRS["ETF"], existing)
    all_failures.extend(fails_etf)
    
    # [æ–°å¢] ä¿å­˜å¤±è´¥æ—¥å¿—
    if all_failures:
        log_df = pd.DataFrame(all_failures)
        log_df.to_csv(FAILED_LOG_FILE, index=False)
        print(f"\nğŸ“ å¤±è´¥æ—¥å¿—å·²ä¿å­˜è‡³: {FAILED_LOG_FILE}")
        print(f"   (å…±è®°å½• {len(all_failures)} æ¡å¼‚å¸¸)")
    else:
        print("\nâœ¨ å®Œç¾è¿è¡Œï¼æ— ä»»ä½•å¤±è´¥è®°å½•ã€‚")

    print("\nğŸ‘‹ ä»»åŠ¡ç»“æŸã€‚")

if __name__ == "__main__":
    main()