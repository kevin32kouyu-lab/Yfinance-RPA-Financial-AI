import yfinance as yf
import pandas as pd
import os
import time
import random
import urllib3
import requests
from tqdm import tqdm

# ==================== 1. é…ç½®åŒºåŸŸ ====================
PROXY_URL = 'http://127.0.0.1:10808'

# è·¯å¾„é…ç½®
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
MSC_PROJECT_ROOT = os.path.dirname(PROJECT_ROOT)
STOCK_DATA_ROOT = os.path.join(MSC_PROJECT_ROOT, "STOCK DATA")

# å®šä¹‰ä¸‰ä¸ªç›®æ ‡å­æ–‡ä»¶å¤¹
DIRS = {
    "ETF": os.path.join(STOCK_DATA_ROOT, "hk_etf_1h"),
    "REIT": os.path.join(STOCK_DATA_ROOT, "hk_reit_1h"),
    "BOND": os.path.join(STOCK_DATA_ROOT, "hk_bond_1h")
}

for d in DIRS.values():
    os.makedirs(d, exist_ok=True)

FAILED_LOG_FILE = os.path.join(CURRENT_DIR, "hk_funds_bonds_failed.csv")
HKEX_URL = "https://www.hkex.com.hk/eng/services/trading/securities/securitieslists/ListOfSecurities.xlsx"

# ==================== 2. ç¯å¢ƒåˆå§‹åŒ– ====================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
os.environ['HTTP_PROXY'] = PROXY_URL
os.environ['HTTPS_PROXY'] = PROXY_URL

# ==================== 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ====================

def get_categorized_tickers():
    print("ğŸ“‹ æ­£åœ¨è·å– HKEX å®˜æ–¹è¯åˆ¸åå•å¹¶åˆ†ç±»...")
    try:
        resp = requests.get(HKEX_URL, verify=False, timeout=30)
        temp_path = os.path.join(CURRENT_DIR, "hk_list_temp_fb.xlsx")
        with open(temp_path, 'wb') as f:
            f.write(resp.content)
            
        # è¯»å– CSV (ä½ çš„æ–‡ä»¶å…¶å®æ˜¯ CSV æ ¼å¼)
        try:
            # å°è¯•ç›´æ¥è¯»å– Excel
            df = pd.read_excel(temp_path, header=2, engine='openpyxl')
        except:
            # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä½œä¸º CSV è¯»å– (å…¼å®¹ä½ ä¸Šä¼ çš„é‚£ä¸ªæ ¼å¼)
            df = pd.read_csv(temp_path, header=2)

        try: os.remove(temp_path)
        except: pass

        if 'Stock Code' not in df.columns or 'Category' not in df.columns:
            print("âŒ å®˜æ–¹åå•æ ¼å¼æœ‰å˜ï¼Œæ— æ³•è§£æï¼")
            print(f"   åˆ—å: {df.columns.tolist()}")
            return None

        # æ¸…æ´— Stock Code
        df['Ticker'] = df['Stock Code'].astype(str).str.extract(r'(\d+)')[0]
        df['Ticker'] = df['Ticker'].str.zfill(4) + ".HK"
        
        # === [ä¿®æ­£] ç²¾ç¡®åˆ†ç±»é€»è¾‘ ===
        # 1. ETFs: å¯¹åº” 'Exchange Traded Products'
        etf_mask = df['Category'] == 'Exchange Traded Products'
        etfs = df[etf_mask]['Ticker'].unique().tolist()
        
        # 2. REITs: å¯¹åº” 'Real Estate Investment Trusts'
        reit_mask = df['Category'] == 'Real Estate Investment Trusts'
        reits = df[reit_mask]['Ticker'].unique().tolist()
        
        # 3. Bonds: å¯¹åº” 'Debt Securities'
        bond_mask = df['Category'] == 'Debt Securities'
        bonds = df[bond_mask]['Ticker'].unique().tolist()

        print(f"âœ… åˆ†ç±»è§£æå®Œæˆ (æ€»è®¡ç›®æ ‡: {len(etfs)+len(reits)+len(bonds)}):")
        print(f"   ğŸ“Š ETFs  : {len(etfs)} åª (å¦‚ 2800.HK)")
        print(f"   ğŸ¢ REITs : {len(reits)} åª (å¦‚ 0823.HK)")
        print(f"   ğŸ“œ Bonds : {len(bonds)} åª (æ³¨æ„ï¼šå€ºåˆ¸å¯èƒ½å¾ˆå¤šä¸ºç©º)")
        
        return {"ETF": etfs, "REIT": reits, "BOND": bonds}
            
    except Exception as e:
        print(f"âŒ è·å–åå•å¤±è´¥: {e}")
        return None

def download_batch(category_name, tickers, save_dir):
    print(f"\nğŸš€ å¼€å§‹æŠ“å– [{category_name}] (ç›®æ ‡: {len(tickers)} åª)")
    
    stats = {"Success": 0, "Skip": 0, "Empty": 0, "Error": 0}
    failed_records = []
    
    pbar = tqdm(tickers, unit="stock")
    
    for ticker in pbar:
        file_name = f"{ticker.replace('.HK', '')}_1h.csv"
        file_path = os.path.join(save_dir, file_name)
        
        if os.path.exists(file_path):
            stats["Skip"] += 1
            continue
            
        try:
            pbar.set_description(f"â¬‡ï¸ {category_name}: {ticker}")
            
            stock = yf.Ticker(ticker)
            df = stock.history(period="2y", interval="1h")
            
            if df.empty:
                stats["Empty"] += 1
                if category_name != "BOND": # å€ºåˆ¸ç©ºå€¼å¤ªæ­£å¸¸äº†ï¼Œä¸è®°å…¥é”™è¯¯æ—¥å¿—ä»¥å…åˆ·å±
                    failed_records.append({"Category": category_name, "Ticker": ticker, "Reason": "Empty Data"})
                continue
                
            if df.index.tz is None:
                df.index = df.index.tz_localize('UTC')
            df.index = df.index.tz_convert('Asia/Hong_Kong')
            
            df.reset_index(inplace=True)
            df['Ticker'] = ticker
            cols = ['Datetime', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume']
            save_df = df[[c for c in cols if c in df.columns]]
            
            if not save_df.empty:
                save_df.to_csv(file_path, index=False)
                stats["Success"] += 1
            else:
                stats["Empty"] += 1

            time.sleep(random.uniform(0.5, 1.5))

        except Exception as e:
            stats["Error"] += 1
            failed_records.append({"Category": category_name, "Ticker": ticker, "Reason": str(e)[:50]})
            time.sleep(1)

    print(f"ğŸ [{category_name}] ç»“æŸ: âœ…{stats['Success']} | ğŸ“­{stats['Empty']} | âŒ{stats['Error']}")
    return failed_records

def main():
    targets = get_categorized_tickers()
    if not targets: return

    all_failed = []
    # ä¾æ¬¡æ‰§è¡Œ
    all_failed.extend(download_batch("ETF", targets["ETF"], DIRS["ETF"]))
    all_failed.extend(download_batch("REIT", targets["REIT"], DIRS["REIT"]))
    all_failed.extend(download_batch("BOND", targets["BOND"], DIRS["BOND"]))
    
    if all_failed:
        df_log = pd.DataFrame(all_failed)
        df_log.to_csv(FAILED_LOG_FILE, index=False, encoding='utf-8-sig')
        print(f"\nğŸ“ å¤±è´¥æ—¥å¿—: {FAILED_LOG_FILE}")
    
    print("\nâœ¨ å…¨éƒ¨å®Œæˆï¼")

if __name__ == "__main__":
    main()