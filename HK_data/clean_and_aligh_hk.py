import pandas as pd
import os
from tqdm import tqdm
import warnings

# å¿½ç•¥è­¦å‘Š
warnings.simplefilter(action='ignore', category=FutureWarning)

# ==================== 1. è·¯å¾„é…ç½® (å…³é”®ä¿®æ­£) ====================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)       # Yfinance RPA
MSC_PROJECT_ROOT = os.path.dirname(PROJECT_ROOT)  # Msc project

# [ä¿®æ­£] æŒ‡å‘é‚£ä¸ªæœ‰ 2730 ä¸ªæ–‡ä»¶çš„æ­£ç¡®è·¯å¾„
# ä¹‹å‰æ˜¯æŒ‡å‘: STOCK DATA/us_stocks_data/hk_1h (âŒ åªæœ‰336ä¸ª)
# ç°åœ¨æ”¹ä¸º:   STOCK DATA/hk_1h             (âœ… æœ‰2730ä¸ª)
SOURCE_DIR = os.path.join(MSC_PROJECT_ROOT, "STOCK DATA", "hk_1h")

# è¾“å‡ºæ–‡ä»¶
OUTPUT_FILE = os.path.join(CURRENT_DIR, "hk_market_data.parquet")

def run_hk_cleaning_final():
    print("="*50)
    print("ğŸ‡­ğŸ‡° æ¸¯è‚¡æ•°æ®æ¸…æ´— (Final Path Fix)")
    print("="*50)
    
    if not os.path.exists(SOURCE_DIR):
        print(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æº: {SOURCE_DIR}")
        return

    csv_files = [f for f in os.listdir(SOURCE_DIR) if f.lower().endswith('.csv')]
    print(f"ğŸ“‚ æ­£ç¡®æ•°æ®æº: {SOURCE_DIR}")
    print(f"ğŸ“ æ‰«æåˆ°æ–‡ä»¶: {len(csv_files)} ä¸ª (è¿™æ‰æ˜¯å¯¹çš„ï¼)")
    
    all_data = []
    print(f"ğŸš€ å¼€å§‹è¯»å– (Standard Mode)...")
    
    for filename in tqdm(csv_files):
        try:
            file_path = os.path.join(SOURCE_DIR, filename)
            
            # === æ ‡å‡†è¯»å– ===
            df = pd.read_csv(file_path)
            
            if df.empty: continue
            
            # 1. æ£€æŸ¥å¿…è¦åˆ—
            if 'Datetime' not in df.columns:
                continue
                
            # 2. è§£ææ—¶é—´ (å…¼å®¹ UTC å­—ç¬¦ä¸²)
            df['Datetime'] = pd.to_datetime(df['Datetime'], utc=True)
            
            # 3. ç»Ÿä¸€è½¬ä¸ºé¦™æ¸¯æ—¶é—´
            df['Datetime'] = df['Datetime'].dt.tz_convert('Asia/Hong_Kong')

            # 4. æå– Ticker
            ticker = filename.replace('_1h.csv', '').replace('.csv', '') + ".HK"
            df['Ticker'] = ticker
            
            # 5. ç»Ÿä¸€åˆ—é¡ºåºå¹¶æ¸…æ´—
            cols = ['Datetime', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume']
            for c in cols:
                if c not in df.columns: df[c] = None
            
            all_aligned = df[cols].copy()
            # ç®€å•å»é‡ï¼Œé˜²æ­¢æœ‰é‡å¤è¡Œ
            all_aligned.drop_duplicates(subset=['Datetime'], inplace=True)
            
            all_data.append(all_aligned)
            
        except Exception:
            continue

    if not all_data:
        print("âŒ æ²¡æœ‰è¯»å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ã€‚")
        return

    # åˆå¹¶
    print(f"\nğŸ“¦ æ­£åœ¨åˆå¹¶ {len(all_data)} åªè‚¡ç¥¨...")
    final_df = pd.concat(all_data, ignore_index=True)
    
    # å¡«å……é€»è¾‘
    print("ğŸ§¹ æ‰§è¡Œ Resampling & Filling (ä¿®å¤æ•°æ®é—´éš™)...")
    final_df = final_df.sort_values(['Ticker', 'Datetime'])
    
    price_cols = ['Open', 'High', 'Low', 'Close']
    final_df[price_cols] = final_df.groupby('Ticker')[price_cols].ffill()
    final_df['Volume'] = final_df['Volume'].fillna(0)
    final_df.dropna(inplace=True)

    # ä¿å­˜
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜è‡³: {OUTPUT_FILE}")
    final_df.to_parquet(OUTPUT_FILE, engine='pyarrow', compression='snappy')
    
    print("="*50)
    print("âœ… å®Œç¾å®Œæˆï¼")
    print(f"ğŸ“Š æœ€ç»ˆæ•°æ®å½¢çŠ¶: {final_df.shape}")
    print(f"ğŸ“‚ æ–‡ä»¶ä½ç½®: {OUTPUT_FILE}")

if __name__ == "__main__":
    run_hk_cleaning_final()