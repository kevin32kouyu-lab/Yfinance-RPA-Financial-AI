import os
import pandas as pd
import glob
from pathlib import Path

# ================= é…ç½®åŒºåŸŸ (å·²æ›´æ–°) =================
# 1. åŸå§‹æ•°æ®è·¯å¾„ (å­˜æ”¾ Raw Data CSVs)
HK_RAW_DIR = r"E:\Msc project\STOCK DATA"

# 2. æ¸…æ´—åçš„ Parquet æ•°æ®è·¯å¾„ (å­˜æ”¾ Cleaned Data)
HK_CLEAN_FILE = r"E:\Msc project\Yfinance RPA\HK_data\hk_unified_market.parquet"
# ===================================================

def get_folder_size_mb(folder_path):
    """è®¡ç®—æ–‡ä»¶å¤¹å¤§å° (MB)"""
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(folder_path):
        for f in filenames:
            fp = os.path.join(dirpath, f)
            if not os.path.islink(fp):
                total_size += os.path.getsize(fp)
    return total_size / (1024 * 1024)

def get_file_size_mb(file_path):
    """è®¡ç®—å•æ–‡ä»¶å¤§å° (MB)"""
    return os.path.getsize(file_path) / (1024 * 1024)

def scan_hk_assets():
    print("="*60)
    print("ğŸ‡­ğŸ‡° é¦™æ¸¯å¸‚åœºæ•°æ®èµ„äº§å®¡è®¡æŠ¥å‘Š (HK Data Audit)")
    print("="*60)

    # --- 1. åŸå§‹æ•°æ®ç»Ÿè®¡ (Raw Data) ---
    print(f"\nğŸ“‚ [Stage 1] åŸå§‹æ•°æ®æ± : {HK_RAW_DIR}")
    if os.path.exists(HK_RAW_DIR):
        csv_files = glob.glob(os.path.join(HK_RAW_DIR, "*.csv"))
        raw_count = len(csv_files)
        raw_size = get_folder_size_mb(HK_RAW_DIR)
        
        print(f"   - æ–‡ä»¶æ•°é‡: {raw_count} ä¸ª CSV")
        print(f"   - å­˜å‚¨å ç”¨: {raw_size:.2f} MB")
        
        if raw_count > 0:
            # æŠ½æ ·æ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡ä»¶
            try:
                sample = pd.read_csv(csv_files[0], nrows=5)
                cols = list(sample.columns)
                print(f"   - æ•°æ®ç»´åº¦: {cols}")
            except:
                pass
    else:
        print("   âŒ è·¯å¾„ä¸å­˜åœ¨ï¼è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")

    # --- 2. æ¸…æ´—åæ•°æ®ç»Ÿè®¡ (Cleaned Data) ---
    print(f"\nğŸ“¦ [Stage 2] ç»“æ„åŒ–æ•°æ®é›†: {HK_CLEAN_FILE}")
    if os.path.exists(HK_CLEAN_FILE):
        try:
            # åªè¯»å–å¿…è¦åˆ—ä»¥åŠ é€Ÿç»Ÿè®¡
            df = pd.read_parquet(HK_CLEAN_FILE, columns=['Ticker', 'Datetime'])
            
            clean_rows = len(df)
            clean_tickers = df['Ticker'].nunique()
            clean_size = get_file_size_mb(HK_CLEAN_FILE)
            min_date = df['Datetime'].min()
            max_date = df['Datetime'].max()
            
            print(f"   - æœ‰æ•ˆè‚¡ç¥¨æ•°: {clean_tickers} åª (ç»è¿‡æ¸…æ´—å»é‡)")
            print(f"   - æ€»æ•°æ®è¡Œæ•°: {clean_rows:,} è¡Œ (OHLCV)")
            print(f"   - æ–‡ä»¶å¤§å°:   {clean_size:.2f} MB (Parquet å‹ç¼©é«˜æ•ˆå­˜å‚¨)")
            print(f"   - æ—¶é—´è·¨åº¦:   {min_date} è‡³ {max_date}")
            
            # å‹ç¼©ç‡è®¡ç®—
            if 'raw_size' in locals() and raw_size > 0:
                ratio = (clean_size / raw_size) * 100
                print(f"   - å­˜å‚¨å‹ç¼©ç‡: çº¦ä¸ºåŸå§‹ä½“ç§¯çš„ {ratio:.1f}% (æ›´é«˜æ•ˆ)")
                
        except Exception as e:
            print(f"   âš ï¸ è¯»å–å¤±è´¥: {e}")
    else:
        print("   âŒ Parquet æ–‡ä»¶ä¸å­˜åœ¨ï¼")

    print("\n" + "="*60)
    print("âœ… ç»Ÿè®¡å®Œæˆã€‚è¯·å°†ä¸Šè¿°æ•°å­—å¡«å…¥ä¸‹æ–¹çš„æ±‡æŠ¥æ¨¡æ¿ä¸­ã€‚")

if __name__ == "__main__":
    scan_hk_assets()