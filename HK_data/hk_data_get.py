import yfinance as yf
import pandas as pd
import os
import time
import random
import urllib3
import requests
from tqdm import tqdm

# ==================== 1. é…ç½®åŒºåŸŸ ====================
# [é…ç½®] ä»£ç†åœ°å€
PROXY_URL = 'http://127.0.0.1:10808'

# è·¯å¾„é…ç½®
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR) 

# --- A. æ•°æ®æ–‡ä»¶ä¿å­˜ä½ç½® (å¤–å±‚ STOCK DATA) ---
# è‡ªåŠ¨å®šä½åˆ°é¡¹ç›®åŒçº§çš„ STOCK DATA æ–‡ä»¶å¤¹
STOCK_DATA_ROOT = os.path.join(os.path.dirname(PROJECT_ROOT), "STOCK DATA")
OUTPUT_SUBDIR = os.path.join(STOCK_DATA_ROOT, "hk_1h")
os.makedirs(OUTPUT_SUBDIR, exist_ok=True)

# --- B. å¤±è´¥æ—¥å¿—ä¿å­˜ä½ç½® (ä¿®æ”¹ä¸ºé¡¹ç›®å†…çš„ output) ---
INTERNAL_OUTPUT_DIR = os.path.join(PROJECT_ROOT, "output")
os.makedirs(INTERNAL_OUTPUT_DIR, exist_ok=True)

FAILED_LOG_FILE = os.path.join(INTERNAL_OUTPUT_DIR, "hk_failed_log.csv")

HKEX_OFFICIAL_LIST_URL = "https://www.hkex.com.hk/eng/services/trading/securities/securitieslists/ListOfSecurities.xlsx"

# ==================== 2. ç¯å¢ƒåˆå§‹åŒ– ====================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
os.environ['HTTP_PROXY'] = PROXY_URL
os.environ['HTTPS_PROXY'] = PROXY_URL
print(f"ğŸŒ å·²é…ç½®ä»£ç†: {PROXY_URL}")

# ==================== 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ====================

def get_precise_hk_tickers():
    """è·å–ç²¾å‡†åå•ï¼ˆå·²è¿‡æ»¤åªä¿ç•™ Equityï¼‰"""
    print("ğŸ“‹ æ­£åœ¨è·å– HKEX å®˜æ–¹è¯åˆ¸åå•...")
    try:
        resp = requests.get(HKEX_OFFICIAL_LIST_URL, verify=False, timeout=30)
        temp_path = os.path.join(CURRENT_DIR, "hk_list_temp.xlsx")
        with open(temp_path, 'wb') as f:
            f.write(resp.content)
            
        df = pd.read_excel(temp_path, header=2, engine='openpyxl')
        try: os.remove(temp_path)
        except: pass

        if 'Stock Code' in df.columns and 'Category' in df.columns:
            # æ ¸å¿ƒè¿‡æ»¤ï¼šåªä¿ç•™æ­£è‚¡ (Equity)
            df_equity = df[df['Category'] == 'Equity'].copy()
            codes = df_equity['Stock Code'].astype(str).str.replace(r'\D', '', regex=True)
            codes = codes[codes.str.len() > 0]
            codes = codes.apply(lambda x: x.zfill(4) + ".HK").unique().tolist()
            print(f"âœ… è·å–æˆåŠŸï¼å·²è¿‡æ»¤è¡ç”Ÿå“ï¼Œå‰©ä½™ {len(codes)} åªæ­£è‚¡ã€‚")
            return codes
            
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è·å–å®˜æ–¹åå• ({e})ï¼Œåˆ‡æ¢è‡³å›é€€æ¨¡å¼ (0001-0999)...")
    
    return [f"{str(i).zfill(4)}.HK" for i in range(1, 9999)]

def run_safe_download():
    tickers = get_precise_hk_tickers()
    total = len(tickers)
    
    print(f"ğŸš€ å¼€å§‹æŠ“å– (ç›®æ ‡: {total} åª | å¸¦å¤±è´¥ç»Ÿè®¡)")
    print(f"ğŸ“‚ æ•°æ®å­˜æ”¾: {OUTPUT_SUBDIR}")
    print(f"ğŸ“ å¤±è´¥æ—¥å¿—: {FAILED_LOG_FILE}")
    
    # ç»Ÿè®¡è®¡æ•°å™¨
    stats = {"Success": 0, "Skip": 0, "Empty": 0, "Error": 0}
    # å¤±è´¥è®°å½•åˆ—è¡¨
    failed_records = []

    pbar = tqdm(tickers, total=total, unit="stock")
    
    for ticker in pbar:
        file_path = os.path.join(OUTPUT_SUBDIR, f"{ticker.replace('.HK', '')}_1h.csv")
        
        # 1. è·³è¿‡å·²å­˜åœ¨
        if os.path.exists(file_path):
            stats["Skip"] += 1
            pbar.set_description(f"â© è·³è¿‡ {ticker}")
            continue
            
        try:
            pbar.set_description(f"â¬‡ï¸ ä¸‹è½½ {ticker}")
            
            # 2. ä¸‹è½½æ•°æ®
            stock = yf.Ticker(ticker)
            df = stock.history(period="2y", interval="1h")
            
            # --- æƒ…å†µ A: æ— æ•°æ® ---
            if df.empty:
                stats["Empty"] += 1
                failed_records.append({"Ticker": ticker, "Reason": "Empty Data (No history found)"})
                continue
                
            # 3. æ—¶åŒºè½¬æ¢
            if df.index.tz is None:
                df.index = df.index.tz_localize('UTC')
            df.index = df.index.tz_convert('Asia/Hong_Kong')
            
            # 4. ä¿å­˜
            df.reset_index(inplace=True)
            df['Ticker'] = ticker
            cols = ['Datetime', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume']
            save_df = df[[c for c in cols if c in df.columns]]
            save_df.to_csv(file_path, index=False)
            
            stats["Success"] += 1
            
            # éšæœºä¼‘çœ 
            time.sleep(random.uniform(1.0, 2.0))

        except Exception as e:
            # --- æƒ…å†µ B: æŠ¥é”™ ---
            stats["Error"] += 1
            error_msg = str(e).replace('\n', ' ')[:100]
            failed_records.append({"Ticker": ticker, "Reason": f"Error: {error_msg}"})
            time.sleep(1)

    print("\n" + "="*40)
    print(f"ğŸ“Š ä»»åŠ¡å®Œæˆ")
    print(f"âœ… æˆåŠŸä¸‹è½½: {stats['Success']}")
    print(f"â© è·³è¿‡å·²å­˜: {stats['Skip']}")
    print(f"ğŸ“­ æ— æ•°æ®  : {stats['Empty']}")
    print(f"âŒ å‘ç”Ÿé”™è¯¯: {stats['Error']}")
    
    # === ä¿å­˜å¤±è´¥æ—¥å¿— ===
    if failed_records:
        df_failed = pd.DataFrame(failed_records)
        df_failed.to_csv(FAILED_LOG_FILE, index=False, encoding='utf-8-sig')
        print(f"ğŸ“ å¤±è´¥è¯¦æƒ…å·²ä¿å­˜è‡³: {FAILED_LOG_FILE}")
    else:
        print("ğŸ‰ å®Œç¾ï¼æ²¡æœ‰å¤±è´¥è®°å½•ã€‚")
    print("="*40)

if __name__ == "__main__":
    run_safe_download()